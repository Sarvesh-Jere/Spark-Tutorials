{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b027132-6312-4c94-9e89-b98094994b88",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+------+-------+------+\n| id|    name|age|salary|address|gender|\n+---+--------+---+------+-------+------+\n|  1|  Manish| 26| 75000|  INDIA|     m|\n|  2|  Nikita| 23|100000|    USA|     f|\n|  3|  Pritam| 22|150000|  INDIA|     m|\n|  4|Prantosh| 17|200000|  JAPAN|     m|\n|  5|  Vikash| 31|300000|    USA|     m|\n|  6|   Rahul| 55|300000|  INDIA|     m|\n|  7|    Raju| 67|540000|    USA|     m|\n|  8| Praveen| 28| 70000|  JAPAN|     m|\n|  9|     Dev| 32|150000|  JAPAN|     m|\n| 10|  Sherin| 16| 25000| RUSSIA|     f|\n| 11|    Ragu| 12| 35000|  INDIA|     f|\n| 12|   Sweta| 43|200000|  INDIA|     f|\n| 13| Raushan| 48|650000|    USA|     m|\n| 14|  Mukesh| 36| 95000| RUSSIA|     m|\n| 15| Prakash| 52|750000|  INDIA|     m|\n+---+--------+---+------+-------+------+\n\n"
     ]
    }
   ],
   "source": [
    "#Read data in spark\n",
    "df=spark.read.format(\"csv\")\\\n",
    "                .option(\"header\",\"true\")\\\n",
    "                .option(\"inferschema\",\"true\")\\\n",
    "                .option(\"mode\",\"permissive\")\\\n",
    "                .load(\"/FileStore/tables/sample_data-1.csv\")\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ce09b5d-567a-4507-97d7-4ed3cae320d2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+------+-------+------+\n| id|    name|age|salary|address|gender|\n+---+--------+---+------+-------+------+\n|  1|  Manish| 26| 75000|  INDIA|     m|\n|  2|  Nikita| 23|100000|    USA|     f|\n|  3|  Pritam| 22|150000|  INDIA|     m|\n|  4|Prantosh| 17|200000|  JAPAN|     m|\n|  5|  Vikash| 31|300000|    USA|     m|\n|  6|   Rahul| 55|300000|  INDIA|     m|\n|  7|    Raju| 67|540000|    USA|     m|\n|  8| Praveen| 28| 70000|  JAPAN|     m|\n|  9|     Dev| 32|150000|  JAPAN|     m|\n| 10|  Sherin| 16| 25000| RUSSIA|     f|\n| 11|    Ragu| 12| 35000|  INDIA|     f|\n| 12|   Sweta| 43|200000|  INDIA|     f|\n| 13| Raushan| 48|650000|    USA|     m|\n| 14|  Mukesh| 36| 95000| RUSSIA|     m|\n| 15| Prakash| 52|750000|  INDIA|     m|\n+---+--------+---+------+-------+------+\n\n"
     ]
    }
   ],
   "source": [
    "#Read corrected and processed data in spark\n",
    "df=spark.read.format(\"csv\")\\\n",
    "                .option(\"header\",\"true\")\\\n",
    "                .option(\"inferschema\",\"true\")\\\n",
    "                .option(\"mode\",\"permissive\")\\\n",
    "                .load(\"/FileStore/tables/employee_data-2.csv\")\n",
    "\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f76081e9-df87-4e88-a6fd-c7829f0a4178",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Use partitionBy in write\n",
    "df.write.format(\"csv\")\\\n",
    "    .option(\"header\",\"true\")\\\n",
    "    .option(\"mode\",\"overwrite\")\\\n",
    "    .option(\"path\",\"/FileStore/tables/employee_data-3_partition\")\\\n",
    "    .partitionBy(\"address\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19c34f0f-870f-4101-8894-699e1f5afd7f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[18]: [FileInfo(path='dbfs:/FileStore/tables/employee_data-3_partition/_SUCCESS', name='_SUCCESS', size=0, modificationTime=1729477431000),\n FileInfo(path='dbfs:/FileStore/tables/employee_data-3_partition/address=INDIA/', name='address=INDIA/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/FileStore/tables/employee_data-3_partition/address=JAPAN/', name='address=JAPAN/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/FileStore/tables/employee_data-3_partition/address=RUSSIA/', name='address=RUSSIA/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/FileStore/tables/employee_data-3_partition/address=USA/', name='address=USA/', size=0, modificationTime=0)]"
     ]
    }
   ],
   "source": [
    "#List the required partitioned files\n",
    "dbutils.fs.ls(\"/FileStore/tables/employee_data-3_partition/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cee001de-9f5a-41a4-9a97-de26be547dd5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Partition using 2 columns that is address and gender\n",
    "df.write.format(\"csv\")\\\n",
    "    .option(\"header\",\"true\")\\\n",
    "    .option(\"mode\",\"overwrite\")\\\n",
    "    .option(\"path\",\"/FileStore/tables/employee_data-3_partition_gender\")\\\n",
    "    .partitionBy(\"address\",\"gender\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83325616-2961-4214-ac0f-bfc56004c948",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[21]: [FileInfo(path='dbfs:/FileStore/tables/employee_data-3_partition_gender/_SUCCESS', name='_SUCCESS', size=0, modificationTime=1729477783000),\n FileInfo(path='dbfs:/FileStore/tables/employee_data-3_partition_gender/address=INDIA/', name='address=INDIA/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/FileStore/tables/employee_data-3_partition_gender/address=JAPAN/', name='address=JAPAN/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/FileStore/tables/employee_data-3_partition_gender/address=RUSSIA/', name='address=RUSSIA/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/FileStore/tables/employee_data-3_partition_gender/address=USA/', name='address=USA/', size=0, modificationTime=0)]"
     ]
    }
   ],
   "source": [
    "#list the partitioned files\n",
    "dbutils.fs.ls(\"/FileStore/tables/employee_data-3_partition_gender/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0c24b1a-86e0-4e0c-8bd9-45ef47bf25ca",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[22]: [FileInfo(path='dbfs:/FileStore/tables/employee_data-3_partition_gender/address=INDIA/gender=f/', name='gender=f/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/FileStore/tables/employee_data-3_partition_gender/address=INDIA/gender=m/', name='gender=m/', size=0, modificationTime=0)]"
     ]
    }
   ],
   "source": [
    "dbutils.fs.ls(\"dbfs:/FileStore/tables/employee_data-3_partition_gender/address=INDIA/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d54ccb47-db1b-4ecf-9458-7cbb601703c9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Using BucketBy in write\n",
    "df.write.format(\"csv\")\\\n",
    "    .option(\"header\",\"true\")\\\n",
    "    .option(\"mode\",\"overwrite\")\\\n",
    "    .option(\"path\",\"/FileStore/tables/employee_data-3_bucket\")\\\n",
    "    .bucketBy(3,\"id\")\\\n",
    "    .saveAsTable(\"bucket_by_id_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe73407a-50ea-438b-8834-dfa19fa2f7de",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[26]: [FileInfo(path='dbfs:/FileStore/tables/employee_data-3_bucket/_SUCCESS', name='_SUCCESS', size=0, modificationTime=1729478474000),\n FileInfo(path='dbfs:/FileStore/tables/employee_data-3_bucket/_committed_2782996082293057971', name='_committed_2782996082293057971', size=306, modificationTime=1729478474000),\n FileInfo(path='dbfs:/FileStore/tables/employee_data-3_bucket/_started_2782996082293057971', name='_started_2782996082293057971', size=0, modificationTime=1729478473000),\n FileInfo(path='dbfs:/FileStore/tables/employee_data-3_bucket/part-00000-tid-2782996082293057971-f70c4b74-f9ff-4dbf-b703-1a2346bf77af-11-1_00000.c000.csv', name='part-00000-tid-2782996082293057971-f70c4b74-f9ff-4dbf-b703-1a2346bf77af-11-1_00000.c000.csv', size=270, modificationTime=1729478473000),\n FileInfo(path='dbfs:/FileStore/tables/employee_data-3_bucket/part-00000-tid-2782996082293057971-f70c4b74-f9ff-4dbf-b703-1a2346bf77af-11-2_00001.c000.csv', name='part-00000-tid-2782996082293057971-f70c4b74-f9ff-4dbf-b703-1a2346bf77af-11-2_00001.c000.csv', size=113, modificationTime=1729478473000),\n FileInfo(path='dbfs:/FileStore/tables/employee_data-3_bucket/part-00000-tid-2782996082293057971-f70c4b74-f9ff-4dbf-b703-1a2346bf77af-11-3_00002.c000.csv', name='part-00000-tid-2782996082293057971-f70c4b74-f9ff-4dbf-b703-1a2346bf77af-11-3_00002.c000.csv', size=115, modificationTime=1729478474000)]"
     ]
    }
   ],
   "source": [
    "#List all the bucketBy files\n",
    "dbutils.fs.ls(\"/FileStore/tables/employee_data-3_bucket\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Partitioning and Bucketing in Spark",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
